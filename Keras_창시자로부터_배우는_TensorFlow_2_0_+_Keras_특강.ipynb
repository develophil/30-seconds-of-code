{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras 창시자로부터 배우는 TensorFlow 2.0 + Keras 특강.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/develophil/30-seconds-of-code/blob/master/Keras_%EC%B0%BD%EC%8B%9C%EC%9E%90%EB%A1%9C%EB%B6%80%ED%84%B0_%EB%B0%B0%EC%9A%B0%EB%8A%94_TensorFlow_2_0_%2B_Keras_%ED%8A%B9%EA%B0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTuxi-1k1F2C",
        "colab_type": "code",
        "outputId": "4b9aa11a-fd6f-429a-9833-5e8990d5d9cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 29.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.33.6)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 42.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.7)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/9e/a48cd34dd7b672ffc227b566f7d16d63c62c58b542d54efa45848c395dd4/tensorboard-2.0.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 27.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0) (41.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.16.0)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/9b/ed0516cc1f7609fb0217e3057ff4f0f9f3e3ce79a369c6af4a6c5ca25664/google_auth-1.6.3-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.7)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.7)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.9.11)\n",
            "\u001b[31mERROR: tensorboard 2.0.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.6.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, google-auth, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed google-auth-1.6.3 tensorboard-2.0.1 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W15eefa2Q5hA",
        "colab_type": "code",
        "outputId": "251b9869-9873-4a75-919b-ea66c83111bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoDjozMFREDU",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow 2.0 + Keras, 딥러닝 연구자들을 위한 오버뷰\n",
        "\n",
        "*@fchollet, October 2019 (번역 @chansung)*\n",
        "- 원본은 [TensorFlow 2.0 + Keras Overview for Deep Learning Researchers](https://colab.research.google.com/drive/1UCJt8EYjlzCs1H1d1X0iDGYJsHKwu-NO?fbclid=IwAR269Y-3J1DuZL01L6GBCC4dg6RSAmJXHnRfztL454dZ5SqKLRxCAZcxzgY)입니다.\n",
        "---\n",
        "\n",
        "**이 문서는 입문, 특강, 그리고 TensorFlow 2.0의 API를 빠르게 참조하는 목적을 위해 제공됩니다.**\n",
        "\n",
        "---\n",
        "\n",
        "TensorFlow와 Keras는 모두 약 4년전쯤 릴리즈 되었습니다 (Keras는 2015년 3월, TensorFlow는 2015년 11월). 이는 딥러닝 세계의 관점에서 볼 때, 꽤 오랜시간이라고 볼 수 있습니다!\n",
        "\n",
        "과거에 TensorFlow 1.x + Keras는 여러가지 알려진 문제점을 가지고 있었습니다:\n",
        "- TensorFlow를 사용한다는것은 정적인 계산 그래프를 조작함을 의미하는것으로, Imperative 코딩 스타일을 사용하는 프로그래머로 하여금 어렵고, 불편한 느낌을 받게 했었습니다.\n",
        "- TensorFlow API가 매우 강력하면서도 유연하지만, 빠른 코드의 작성의 가능성이 결여되어 있었으며 종종 사용법은 어렵고 혼란스러웠습니다.\n",
        "- Keras는 매우 생산적이고 사용이 쉽지만, 연구에 사용된 사례에서 종종 유연성이 결여되었었습니다.\n",
        "\n",
        "---\n",
        "### TensorFlow 2.0은 TensorFlow와 Keras를 대대적으로 새로이 디자인한 것으로, 지난 4년간의 사용자 피드백과 기술의 진보가 모두 고려되었습니다. 위에서 언급된 문제점들을 대규모로 수정합니다.\n",
        "\n",
        "### 미래에서온 차세대 머신러닝 플랫폼입니다\n",
        "\n",
        "---\n",
        "\n",
        "TensorFlow 2.0은 아래와 같은 주요 아이디어에 기반하고 있습니다:\n",
        "\n",
        "- 사용자들이 계산을 eagerly하게 수행할 수 있게 해줍니다. 이는 Numpy를 사용하는법과 유사합니다. 이는 TensorFlow 2.0을 이용한 프로그래밍이 직관적이며 동시에 파이토닉할 수 있게끔 해 줍니다.\n",
        "- 컴파일된 그래프의 엄청난 이점을 그대로 보존하는데, 이는 성능, 분산, 그리고 배포를 위함입니다. 이 내용은 TensorFlow를 빠르고, 분산 구조에서의 확장 가능하며, 상용화에 준비될 수 있도록 해 줍니다.\n",
        "- Keras를 딥러닝의 고수준 API로 채택하여, TensorFlow를 이해하기 쉬우면서도 높은 생산성을 가질 수 있게 만들어 줍니다.\n",
        "- 매우 고수준(더 쉬운 사용성, 약간 부족한 유연성) 에서부터 매우 저수준(더 깊은 전문성, 매우 뛰어난 유연성)의 다양한 범위의 작업으로까지 Keras를 확장합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U71NYDeFkUhq",
        "colab_type": "text"
      },
      "source": [
        "# 파트 1: TensorFlow의 기본"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2e8-qrcl2kH",
        "colab_type": "text"
      },
      "source": [
        "## Tensors (텐서)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX6JvH4h0zyY",
        "colab_type": "text"
      },
      "source": [
        "다음은 [상수형](https://www.tensorflow.org/api_docs/python/tf/constant) 텐서 입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGB6GDsfRFJs",
        "colab_type": "code",
        "outputId": "2ccc6674-1438-4073-eb78-334ad2cd98d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x = tf.constant([[5, 2], [1, 3]])\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[5 2]\n",
            " [1 3]], shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX2SB_2O1jx7",
        "colab_type": "text"
      },
      "source": [
        "해당 텐서의 값을 Numpy 배열형태로 가져오고 싶다면 `.numpy()`를 호출하면 됩니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwGyHOoq1oWn",
        "colab_type": "code",
        "outputId": "467ed4e5-370f-4ee8-b890-d41954fdb1da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x.numpy()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 2],\n",
              "       [1, 3]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNkno66r1xvg",
        "colab_type": "text"
      },
      "source": [
        "Numpy 배열과 *꽤나* 유사한 점으로 `dtype`과 `shape`이라는 속성을 가집니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSxtblSP13v2",
        "colab_type": "code",
        "outputId": "7c772652-5106-4365-fa43-729b950b2060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('dtype:', x.dtype)\n",
        "print('shape:', x.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dtype: <dtype: 'int32'>\n",
            "shape: (2, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oogzv3--2EF2",
        "colab_type": "text"
      },
      "source": [
        "상수형 텐서를 생성하는 보편적인 방법은 `tf.ones`과 `tf.zeros`를 사용하는 것입니다(이는 Numpy의 `np.ones` 및 `np.zeros`와 유사합니다):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qDlfa8r2Lia",
        "colab_type": "code",
        "outputId": "109cb312-e4f8-4439-a2f3-3247ae6ce44b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(tf.ones(shape=(2, 1)))\n",
        "print(tf.zeros(shape=(2, 1)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1.]\n",
            " [1.]], shape=(2, 1), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.]\n",
            " [0.]], shape=(2, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewGG2vZaXzRW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b011d8cb-6400-450b-cf47-99a9db05b19f"
      },
      "source": [
        "import numpy as np\n",
        "np.ones(shape=(2, 1))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzGYEkdcmYbe",
        "colab_type": "text"
      },
      "source": [
        "## 랜덤한 상수형 텐서"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk94gREJ2r-e",
        "colab_type": "text"
      },
      "source": [
        "다음은 랜덤한 [정규분포](https://www.tensorflow.org/api_docs/python/tf/random/normal)로부터 상수를 생성합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqRrO-Puma7-",
        "colab_type": "code",
        "outputId": "bc39ca52-74af-4389-a3a5-7e020a0a916a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "tf.random.normal(shape=(2, 2), mean=0., stddev=1.)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=18, shape=(2, 2), dtype=float32, numpy=\n",
              "array([[-2.0440261,  1.0700499],\n",
              "       [-0.7056884, -1.1177964]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL0EMPT93SEU",
        "colab_type": "text"
      },
      "source": [
        "*그리고* 다음은 랜덤한 [균등분포](https://www.tensorflow.org/api_docs/python/tf/random/uniform)로부터 값이 채워지는 정수형 텐서를 보여줍니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9syARhtj2wbx",
        "colab_type": "code",
        "outputId": "d1bf72b0-1db9-4ac1-8975-8b1063844c3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "tf.random.uniform(shape=(2, 2), minval=0, maxval=10, dtype='int32')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=22, shape=(2, 2), dtype=int32, numpy=\n",
              "array([[3, 9],\n",
              "       [6, 3]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I95066exmbDU",
        "colab_type": "text"
      },
      "source": [
        "## Variables (변수)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMflzgPM3Mim",
        "colab_type": "text"
      },
      "source": [
        "[Variables](https://www.tensorflow.org/guide/variable)는 변할 수 있는 상태(뉴럴넷의 가중치와 같은)를 저장하는데 사용되는 특별한 텐서 입니다. 초기값을 사용해서 Variable을 생성할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FvENXmBmcyT",
        "colab_type": "code",
        "outputId": "ebf952b3-b0d0-4357-d3ba-032f33897127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "initial_value = tf.random.normal(shape=(2, 2))\n",
        "a = tf.Variable(initial_value)\n",
        "print(a)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[-0.02311571, -0.5107567 ],\n",
            "       [-0.94115275,  0.21887831]], dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRFwVySi3biu",
        "colab_type": "text"
      },
      "source": [
        "`.assign(value)`, `.assign_add(increment)`, 또는 `.assign_sub(decrement)`와 같은 메소드를 사용해서 Variable의 값을 갱신합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOCsCNvc3mNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_value = tf.random.normal(shape=(2, 2))\n",
        "a.assign(new_value)\n",
        "for i in range(2):\n",
        "  for j in range(2):\n",
        "    assert a[i, j] == new_value[i, j]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrSjwl_056j8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "added_value = tf.random.normal(shape=(2, 2))\n",
        "a.assign_add(added_value)\n",
        "for i in range(2):\n",
        "  for j in range(2):\n",
        "    assert a[i, j] == new_value[i, j] + added_value[i, j]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAIqYQmOl_wR",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow에서 수학을 하는것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bmtTepn6SvG",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow는 Numpy를 사용하는것과 정확히 똑같은 방법으로 사용할 수 있습니다. 이 둘의 주요 다른점은 작성한 TensorFlow의 코드는 GPU와 TPU 상에서 실행될 수 있다는 점입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCZGHQ_XmHuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = tf.random.normal(shape=(2, 2))\n",
        "b = tf.random.normal(shape=(2, 2))\n",
        "\n",
        "c = a + b\n",
        "d = tf.square(c)\n",
        "e = tf.exp(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Feq3qWoBVQW",
        "colab_type": "text"
      },
      "source": [
        "## `GradientTape`을 사용해서 경사도를 계산하는것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdsmOcrJBWXe",
        "colab_type": "text"
      },
      "source": [
        "한 가지 더 Numpy와의 큰 차이점이 있습니다: 모든 미분가능한 표현에 대해서, 자동으로 경사도를 구하는 것이 가능합니다.\n",
        "\n",
        "단순히 [`GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape)를 열게되면, 그때부턴 `tape.watch()`를 통해 텐서를 확인하고, 이 텐서를 입력으로써 사용하는 미분가능한 표현을 구성하는것이 가능합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkEAY45IBjPv",
        "colab_type": "code",
        "outputId": "2f2668ed-b22c-4ff1-e215-a3c5c0356698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "a = tf.random.normal(shape=(2, 2))\n",
        "b = tf.random.normal(shape=(2, 2))\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  tape.watch(a)  # `a`에 적용되는 연산의 히스토리에 대한 기록을 시작\n",
        "  c = tf.sqrt(tf.square(a) + tf.square(b))  # `a`를 사용하여 몇 가지 수학을 수행\n",
        "  # `a`에 대한 `c`의 경사도는 무엇인가?\n",
        "  dc_da = tape.gradient(c, a)\n",
        "  print(dc_da)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.00822217 -0.97261304]\n",
            " [ 0.8036699   0.9800323 ]], shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8UpqFx_DDbV",
        "colab_type": "text"
      },
      "source": [
        "디폴트로는 Variable들은 자동으로 watch가 적용되어 있기 때문에, 수동으로 `watch`를 해 줄 필요는 없습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtH3FuvDDOAY",
        "colab_type": "code",
        "outputId": "6cc24252-2608-4c1e-e918-403723968de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "a = tf.Variable(a)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  c = tf.sqrt(tf.square(a) + tf.square(b))\n",
        "  dc_da = tape.gradient(c, a)\n",
        "  print(dc_da)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.9645925   0.6490695 ]\n",
            " [ 0.30492076 -0.5009346 ]], shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFlBGjuEDbt-",
        "colab_type": "text"
      },
      "source": [
        "GradientTape을 중첩시켜서 고차원의 미분을 계산할 수도 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjPcY0OIDhEA",
        "colab_type": "code",
        "outputId": "3a0ea2d6-6f29-4acf-d1d2-db5798e7bd1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "with tf.GradientTape() as outer_tape:\n",
        "  with tf.GradientTape() as tape:\n",
        "    c = tf.sqrt(tf.square(a) + tf.square(b))\n",
        "    dc_da = tape.gradient(c, a)\n",
        "  d2c_da2 = outer_tape.gradient(dc_da, a)\n",
        "  print(d2c_da2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.06331927 0.40539196]\n",
            " [0.8402547  0.35901004]], shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC5RgwGeBP-9",
        "colab_type": "text"
      },
      "source": [
        "## end-to-end 예제: 선형 회귀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Owbx4mlEErNN",
        "colab_type": "text"
      },
      "source": [
        "지금까지 TensorFlow는 Numpy와 비슷한 라이브러리인데, 추가적으로 GPU 또는 TPU를 통해 가속될 수 있고, 자동으로 미분이 계산된다는 내용을 배웠습니다. 그러면 이제는 end-to-end 예제를 알아볼 시간입니다: 머신러닝의 피즈버즈인, 선형 회귀를 구현해 봅시다. \n",
        "\n",
        "이를 보여주기 위해서, `Layer` 또는 `MeanSquaredError`와 같은 Keras의 고수준 컴포넌트를 사용하지 않을 것입니다. 단지 기본적인 연산자만을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhitqoj2FH8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = 2\n",
        "output_dim = 1\n",
        "learning_rate = 0.01\n",
        "\n",
        "# 가중치 행렬입니다\n",
        "w = tf.Variable(tf.random.uniform(shape=(input_dim, output_dim)))\n",
        "# 편향 벡터입니다\n",
        "b = tf.Variable(tf.zeros(shape=(output_dim,)))\n",
        "\n",
        "def compute_predictions(features):\n",
        "  return tf.matmul(features, w) + b\n",
        "\n",
        "def compute_loss(labels, predictions):\n",
        "  return tf.reduce_mean(tf.square(labels - predictions))\n",
        "\n",
        "def train_on_batch(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = compute_predictions(x)\n",
        "    loss = compute_loss(y, predictions)\n",
        "    dloss_dw, dloss_db = tape.gradient(loss, [w, b])\n",
        "  w.assign_sub(learning_rate * dloss_dw)\n",
        "  b.assign_sub(learning_rate * dloss_db)\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC1fp3BYJeXo",
        "colab_type": "text"
      },
      "source": [
        "작성한 모델을 검증하기 위한, 인공적인 데이터를 생성해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ocAkrliMVAQ",
        "colab_type": "code",
        "outputId": "7dbdcb46-8413-4e4b-de05-d691d6eac801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# 데이터셋을 준비합니다\n",
        "num_samples = 10000\n",
        "negative_samples = np.random.multivariate_normal(\n",
        "    mean=[0, 3], cov=[[1, 0.5],[0.5, 1]], size=num_samples)\n",
        "positive_samples = np.random.multivariate_normal(\n",
        "    mean=[3, 0], cov=[[1, 0.5],[0.5, 1]], size=num_samples)\n",
        "features = np.vstack((negative_samples, positive_samples)).astype(np.float32)\n",
        "labels = np.vstack((np.zeros((num_samples, 1), dtype='float32'),\n",
        "                    np.ones((num_samples, 1), dtype='float32')))\n",
        "\n",
        "plt.scatter(features[:, 0], features[:, 1], c=labels[:, 0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f8c597a87b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngeMUAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCdZTpjlJlGo",
        "colab_type": "text"
      },
      "source": [
        "그러면, 데이터의 배치크기 단위로 돌면서, `train_on_batch` 함수를 반복적으로 호출하여 선형 회귀 모델을 학습시켜 봅시다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsHszjjaJDQZ",
        "colab_type": "code",
        "outputId": "a86bcc74-355b-4bc8-8052-5d44abc447d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# 데이터를 무작위로 섞습니다\n",
        "random.Random(1337).shuffle(features)\n",
        "random.Random(1337).shuffle(labels)\n",
        "\n",
        "# 손쉽게 배치화된 반복을 위해, tf.data.Dataset 객체를 생성합니다\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(256)\n",
        "\n",
        "for epoch in range(10):\n",
        "  for step, (x, y) in enumerate(dataset):\n",
        "    loss = train_on_batch(x, y)\n",
        "  print('Epoch %d: 마지막 배치의 손실값 = %.4f' % (epoch, float(loss)))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 마지막 배치의 손실값 = 0.0881\n",
            "Epoch 1: 마지막 배치의 손실값 = 0.0626\n",
            "Epoch 2: 마지막 배치의 손실값 = 0.0429\n",
            "Epoch 3: 마지막 배치의 손실값 = 0.0392\n",
            "Epoch 4: 마지막 배치의 손실값 = 0.0380\n",
            "Epoch 5: 마지막 배치의 손실값 = 0.0311\n",
            "Epoch 6: 마지막 배치의 손실값 = 0.0299\n",
            "Epoch 7: 마지막 배치의 손실값 = 0.0132\n",
            "Epoch 8: 마지막 배치의 손실값 = 0.0185\n",
            "Epoch 9: 마지막 배치의 손실값 = 0.0312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIDDhTcyJwSM",
        "colab_type": "text"
      },
      "source": [
        "아래는 우리가 만든 모델이 얼마나 잘 동작하는지를 보여줍니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBPYQpskJxxT",
        "colab_type": "code",
        "outputId": "095492de-16b7-42d6-dffb-12daefb93182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "predictions = compute_predictions(features)\n",
        "plt.scatter(features[:, 0], features[:, 1], c=predictions[:, 0] > 0.5)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f8c5871fbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBcqiop7mH7x",
        "colab_type": "text"
      },
      "source": [
        "## `tf.function`를 이용해서 속도를 빠르게 하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjZ8kuruNdj6",
        "colab_type": "text"
      },
      "source": [
        "현재의 코드는 얼마나 빨리 수행될까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXoe7S5RmStB",
        "colab_type": "code",
        "outputId": "82452182-2920-491d-d8d1-77d3f72e758b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "for epoch in range(20):\n",
        "  for step, (x, y) in enumerate(dataset):\n",
        "    loss = train_on_batch(x, y)\n",
        "t_end = time.time() - t0\n",
        "print('epoch당 걸린 시간: %.3f 초' % (t_end / 20,))\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch당 걸린 시간: 0.183 초\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHsvPqyRN_E3",
        "colab_type": "text"
      },
      "source": [
        "학습 함수를 정적 그래프로 컴파일 해 봅시다. 이를 위해서 해야할 것은 문자 그대로, `tf.function`이라는 데코레이터를 위에 넣어주는것 뿐입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEYFkThcOGcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_on_batch(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = compute_predictions(x)\n",
        "    loss = compute_loss(y, predictions)\n",
        "    dloss_dw, dloss_db = tape.gradient(loss, [w, b])\n",
        "  w.assign_sub(learning_rate * dloss_dw)\n",
        "  b.assign_sub(learning_rate * dloss_db)\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocOuskvoOKsx",
        "colab_type": "text"
      },
      "source": [
        "다시한번 시간을 측정해 봅시다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT2w6DVmONB5",
        "colab_type": "code",
        "outputId": "a0d3d78d-241d-4bb9-a047-9bf1262f0a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t0 = time.time()\n",
        "for epoch in range(20):\n",
        "  for step, (x, y) in enumerate(dataset):\n",
        "    loss = train_on_batch(x, y)\n",
        "t_end = time.time() - t0\n",
        "print('epoch당 걸린 시간: %.3f 초' % (t_end / 20,))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch당 걸린 시간: 0.097 초\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYPWZaSqOfEL",
        "colab_type": "text"
      },
      "source": [
        "걸린 시간이 약 40% 감소했습니다. 이 경우, 매우 간단한 모델을 사용했습니다; 일반적으로 모델이 크면 클 수록, 정적 그래프를 활용한 속도 개선은 더 많이 이뤄집니다.\n",
        "\n",
        "기억해야할 것이 있습니다: eager 실행모드는 디버깅과 코드 라인별 결과를 출력하는데 매우 유용하지만, 크기를 키워야할 시기가 오면, 정적 그래프가 연구자들에게 최고의 친구가 될 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3I3v_FqjFty",
        "colab_type": "text"
      },
      "source": [
        "# 파트 2: Keras API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjLI719fPfJi",
        "colab_type": "text"
      },
      "source": [
        "Keras는 딥러닝을 위한 파이썬 API 입니다. 모두가 사용할만한 내용을 가지고 있습니다:\n",
        "\n",
        "- 엔지니어의 경우, Keras는 계층, 평가지표(metrics), 학습 반복문과 같은 재사용 가능한 블록을 제공하여 일반적은 사용 사례를 지원합니다. 고수준의 사용자 경험을 제공하여 접근이 용이하고, 생산성이 좋습니다.\n",
        "\n",
        "- 연구자의 경우, 계층이나 학습 반목문과 같은 이미 제공되는 블록의 사용을 선호하지 않고, 스스로 만든 것을 대신 사용할 지도 모릅니다. 물론, Keras는 이를 가능하게 해 줍니다. 이 경우, Keras는 여러분이 작성하게될 블록에 대한 템플릿을 Layers 및 Metrics와 같은 표준적인 API와 함께 제공합니다. 이러한 구조는 다른 사람과 코드를 쉽게 공유하고, 상용의 작업 흐름에도 통합될 수 있게끔 해 줍니다.\n",
        "\n",
        "- 이 같은 내용은 라이브러리를 개발하는 분들에게도 적용되는 사실입니다. TensorFlow는 거대한 생태계죠. 수 많은 라이브러리가 존재합니다. 서로다른 라이브러리가 상호작용하고, 이들의 컴포넌트를 공유할 수 있게하기 위해선 API 표준을 따라야만 합니다. API 표준이 곧 Keras가 제공하는 핵심입니다.\n",
        "\n",
        "\n",
        "Keras는 결정적으로 고수준의 UX와 저수준의 유연성을 모두 함께 완만히 도입합니다. 이는 더이상 한편으론 사용성이 뛰어나지만 유연치는 못한 고수준 API를, 다른 한편으론 매우 유연하지만 전문가만이 사용가능한 저수준 API를 가져야만 하는 상황에서 벗어나게 해 줍니다. 그 대신, 매우 고수준에서부터 매우 저수준 까지의 다양한 작업 흐름의 범위를 가질 수 있게 됩니다. 이 작업흐름이란, 동일한 컨셉과 객체에 기반해서 만들어졌기 때문에 모든것이 상호 호환 가능한 것을 의미합니다.\n",
        "\n",
        "![Keras 작업 흐름의 범위](https://drive.google.com/uc?export=view&id=1bE0FiQY2XF5QzBLRHfe7-SdxvwGIO0GK)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9DSVjdHPkOw",
        "colab_type": "text"
      },
      "source": [
        "## `Layer` 기본 클래스\n",
        "\n",
        "가장 첫 번째로 알아야할 클래스는 [`Layer`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer) 입니다. Keras의 거의 모든것은 이 클래스로부터 파생됩니다.\n",
        "\n",
        "Layer는 상태(가중치, weights)와 몇 (`call` 메소드에 정의된)계산을 캡슐화 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io3dUQzaPnPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "class Linear(Layer):\n",
        "  \"\"\"y = w.x + b\"\"\"\n",
        "\n",
        "  def __init__(self, units=32, input_dim=32):\n",
        "      super(Linear, self).__init__()\n",
        "      w_init = tf.random_normal_initializer()\n",
        "      self.w = tf.Variable(\n",
        "          initial_value=w_init(shape=(input_dim, units), dtype='float32'),\n",
        "          trainable=True)\n",
        "      b_init = tf.zeros_initializer()\n",
        "      self.b = tf.Variable(\n",
        "          initial_value=b_init(shape=(units,), dtype='float32'),\n",
        "          trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "      return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "# 우리가 만든 Layer객체를 인스턴스화 합니다\n",
        "linear_layer = Linear(4, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo3etyK8BO4a",
        "colab_type": "text"
      },
      "source": [
        "Layer 인스턴스는 마치 함수처럼 동작합니다. 몇 데이터에 대해서 이를 호출해 봅시다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBUCLfHVBQLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = linear_layer(tf.ones((2, 2)))\n",
        "assert y.shape == (2, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXqpznsxBaCC",
        "colab_type": "text"
      },
      "source": [
        "`Layer` 클래스는 속성으로써 부여된 weights를 통해서, 가중치들을 추적합니다 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_FaUtEYBeJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 가중치는 자동으로 `weights`라는 속성으로써 추적됩니다.\n",
        "assert linear_layer.weights == [linear_layer.w, linear_layer.b]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6PZ6QXUHdxA",
        "colab_type": "text"
      },
      "source": [
        "`add_weight`를 이용하여 간단히 가중치를 생성하는 방법이 있는것도 알아두세요. 이렇게 코드를 작성하는것 대신:\n",
        "\n",
        "```python\n",
        "w_init = tf.random_normal_initializer()\n",
        "self.w = tf.Variable(initial_value=w_init(shape=shape, dtype='float32'))\n",
        "```\n",
        "\n",
        "일반적으로 아래와 같이 작성합니다:\n",
        "\n",
        "```python\n",
        "self.w = self.add_weight(shape=shape, initializer='random_normal')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lphpMGIiHRUP",
        "colab_type": "text"
      },
      "source": [
        "`build`라는 별도의 메소드에서 가중치를 생성하는것이 좋은 관례입니다. 이 `build`는 Layer에 의해 첫 번째 입력의 Shape이 확인되는 순간 호출되는 lazy한 메소드 입니다. 이러한 패턴은 입력 차원(input_dim)을 생성자에 명시하지 않아도 되게 해 줍니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpPjScZKHXhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Linear(Layer):\n",
        "  \"\"\"y = w.x + b\"\"\"\n",
        "\n",
        "  def __init__(self, units=32):\n",
        "      super(Linear, self).__init__()\n",
        "      self.units = units\n",
        "\n",
        "  def build(self, input_shape):\n",
        "      self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                               initializer='random_normal',\n",
        "                               trainable=True)\n",
        "      self.b = self.add_weight(shape=(self.units,),\n",
        "                               initializer='random_normal',\n",
        "                               trainable=True)\n",
        "\n",
        "  def call(self, inputs):\n",
        "      return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "\n",
        "# Lazy한 Layer의 인스턴스를 만듭니다.\n",
        "linear_layer = Linear(4)\n",
        "\n",
        "# 이렇게 하면, `build(input_shape)`이 호출되어 가중치를 생성하게 됩니다.\n",
        "y = linear_layer(tf.ones((2, 2)))\n",
        "assert len(linear_layer.weights) == 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86khdsF3Pnr0",
        "colab_type": "text"
      },
      "source": [
        "## 학습 가능한, 그리고 학습 불가능한 가중치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32zvCEKLICr5",
        "colab_type": "text"
      },
      "source": [
        "Layer에 의해 생성된 가중치는 학습이 가능할 수도, 학습이 불가능할 수도 있습니다. 이 두 경우는 각각 \n",
        "`trainable_weights` 및 `non_trainable_weights`로써 노출되어 외부에서 접근 가능합니다. 다음은 학습 불가능한 가중치를 가지는 Layer를 보여줍니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ8s28NnX20u",
        "colab_type": "code",
        "outputId": "532d4d86-9dbc-4fa9-fc44-23b9efa10654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "class ComputeSum(Layer):\n",
        "  \"\"\"입력의 합산 결과를 반환하는 Layer\"\"\"\n",
        "\n",
        "  def __init__(self, input_dim):\n",
        "      super(ComputeSum, self).__init__()\n",
        "      # 학습 불가능한 가중치를 생성합니다.\n",
        "      self.total = tf.Variable(initial_value=tf.zeros((input_dim,)),\n",
        "                               trainable=False)\n",
        "\n",
        "  def call(self, inputs):\n",
        "      self.total.assign_add(tf.reduce_sum(inputs, axis=0))\n",
        "      return self.total  \n",
        "\n",
        "my_sum = ComputeSum(2)\n",
        "x = tf.ones((2, 2))\n",
        "\n",
        "y = my_sum(x)\n",
        "print(y.numpy())  # [2. 2.]\n",
        "\n",
        "y = my_sum(x)\n",
        "print(y.numpy())  # [4. 4.]\n",
        "\n",
        "assert my_sum.weights == [my_sum.total]\n",
        "assert my_sum.non_trainable_weights == [my_sum.total]\n",
        "assert my_sum.trainable_weights == []"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2.]\n",
            "[4. 4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oBkX6ZfYO8j",
        "colab_type": "text"
      },
      "source": [
        "## 재귀적으로 Layer를 조합하는것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeLDL9MJI2dK",
        "colab_type": "text"
      },
      "source": [
        "Layer들은 더 큰 계산을 위한 블록을 생성하기 위해 재귀적으로 중첩될 수 있습니다. 각각의 Layer는 각각의 (학습 가능한것과 학습 불가능한)가중치를 추적할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5HBH-dtYQuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# `build` 메소드와 함께 앞서 정의된\n",
        "# Linear 클래스를 재사용 해봅시다\n",
        "\n",
        "class MLP(Layer):\n",
        "    \"\"\"Linear Layer의 간단한 층을 쌓는 Layer 입니다.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.linear_1 = Linear(32)\n",
        "        self.linear_2 = Linear(32)\n",
        "        self.linear_3 = Linear(10)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.linear_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.linear_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        return self.linear_3(x)\n",
        "\n",
        "mlp = MLP()\n",
        "\n",
        "# `mlp` 객체에 대한 첫 번째 호출은 가중치를 생성하게 됩니다.\n",
        "y = mlp(tf.ones(shape=(3, 64)))\n",
        "\n",
        "# 가중치들은 재귀적으로 추적됩니다.\n",
        "assert len(mlp.weights) == 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WavMVtXGQk-z",
        "colab_type": "text"
      },
      "source": [
        "## 미리 정의된 Layer의 종류\n",
        "\n",
        "Keras는 [넓은 범위의 미리 정의된 Layer의 종류](https://www.tensorflow.org/api_docs/python/tf/keras/layers/)를 제공하여 항상 여러분 스스로가 모든것을 구현하지 않아도 되도록끔 해 줍니다.\n",
        "\n",
        "- Convolution layers\n",
        "- Transposed convolutions\n",
        "- Separateable convolutions\n",
        "- Average and max pooling\n",
        "- Global average and max pooling\n",
        "- LSTM, GRU (with built-in cuDNN acceleration)\n",
        "- BatchNormalization\n",
        "- Dropout\n",
        "- Attention\n",
        "- ConvLSTM2D\n",
        "- etc.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdrw7OppQ6At",
        "colab_type": "text"
      },
      "source": [
        "Keras는 디폴트로 좋은 설정값을 노출시키는 원칙을 따릅니다. 이렇게 해서, 필요한 인자값을 디폴트값으로 내버려두어도 대부분의 경우에서 잘 동작할 수 있게끔 해 줍니다. 예를 들어서, `LSTM` Layer는 디폴트로 직교 순환 행렬 초기화자(orthogonal recurrent matrix intializer)를 사용하고, 이는 forget 게이트의 편향값을 1로써 초기화 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oq88tadFz8Z",
        "colab_type": "text"
      },
      "source": [
        "## `call` 메소드의 `training` 인자\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2NkTT0AQV8j",
        "colab_type": "text"
      },
      "source": [
        "몇 Layer, 특히 `BatchNormalization`과 `Dropout` Layer,는 학습과 추론단계에서 서로다른 동작방식을 가집니다. 이러한 종류의 Layer에 대해선, `call` 메소으의 (부울 형식인)`training` 인자를 노출시키는 것이 표준적인 관례입니다.\n",
        "\n",
        "`call` 메소드의 이 인자를 노출시킴으로써, 미리 제공되는 학습과 평가 반복문(예를 들어서 `fit` 메소드)이 해당 Layer를 학습과 추론에 대해서 옳바르게 사용할 수 있게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysXzHB5KJiLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dropout(Layer):\n",
        "  \n",
        "  def __init__(self, rate):\n",
        "    super(Dropout, self).__init__()\n",
        "    self.rate = rate\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "    if training:\n",
        "      return tf.nn.dropout(inputs, rate=self.rate)\n",
        "    return inputs\n",
        "\n",
        "class MLPWithDropout(Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "      super(MLPWithDropout, self).__init__()\n",
        "      self.linear_1 = Linear(32)\n",
        "      self.dropout = Dropout(0.5)\n",
        "      self.linear_3 = Linear(10)\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "      x = self.linear_1(inputs)\n",
        "      x = tf.nn.relu(x)\n",
        "      x = self.dropout(x, training=training)\n",
        "      return self.linear_3(x)\n",
        "    \n",
        "mlp = MLPWithDropout()\n",
        "y_train = mlp(tf.ones((2, 2)), training=True)\n",
        "y_test = mlp(tf.ones((2, 2)), training=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyC7KfV-YcYS",
        "colab_type": "text"
      },
      "source": [
        "## 좀 더 함수형적으로 모델을 정의하기 위한 방법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxbEQANKQB6F",
        "colab_type": "text"
      },
      "source": [
        "딥 러닝 모델을 만들기 위해서, 항상 객체지향적 프로그래밍 방법을 사용할 필요는 없습니다. 아래의 예시처럼 Layer들은 함수형적으로도 조합이 가능합니다 (\"함수형 API\" 라고 부릅니다):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiL-0N7sYc6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# `Input` 객체를 사용해서, 입력의 shape(모양)과 dtype(데이터형)을 묘사합니다.\n",
        "# 딥러닝에서 이는 데이터형을 선언하는 방식입니다.\n",
        "# shape 인자는 샘플당 으로, 배치 크기를 포함하지 않습니다. \n",
        "# 함수형 API는 샘플당 변형을 정의하는데 집중합니다.\n",
        "# 생성하는 모델은 자동으로 샘플당 변형에 대한 배치를 고려합니다.\n",
        "# 따라서, 모델은 데이터의 배치마다 호출됩니다.\n",
        "inputs = tf.keras.Input(shape=(16,))\n",
        "\n",
        "# 이러한 \"데이터형\"의 객체에 대해서 Layer를 호출하고,\n",
        "# 호출 결과로 갱신된 (새로운 shape과 dtype을 가지는)\"데이터형\"을 반환합니다.\n",
        "x = Linear(32)(inputs) # 앞서 정의된 Linear Layer를 재사용 합니다.\n",
        "x = Dropout(0.5)(x)    # 앞서 정의된 Droptout Layer를 재사용 합니다.\n",
        "outputs = Linear(10)(x)\n",
        "\n",
        "# 함수형 `모델(Model)`은 입력과 출력을 명시하여 정의될 수 있습니다.\n",
        "# 모델은 다른것과 마찬가지로 스스로가 또 하나의 Layer가 됩니다.\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 함수형 모델은 호출되기전, 이미 가중치를 가집니다.\n",
        "# 그 이유는 입력에 대한 shape을 `input`에서 사전에 정의했기 때문입니다.\n",
        "assert len(model.weights) == 4\n",
        "\n",
        "# 똑같은 데이터에 대해서, 모델을 다시 호출해 봅시다.\n",
        "y = model(tf.ones((2, 16)))\n",
        "assert y.shape == (2, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK5HqnT3Xgcz",
        "colab_type": "text"
      },
      "source": [
        "함수형 API는 하위 클래스를 만드는것 보다 더 간결하고, 여기엔 몇몇 부가적인 이점(일반적으로 함수형, 형 선언적 언어가 형 선언적이지 않은 객체지향 개발에 비해 가지는 이점과 동일)이 존재합니다. 하지만, 이는 Layer들의 DAGs를 정의하는데에만 사용될 수 있습니다. 재귀적인 네트워크는 `Layer`의 하위 클래스를 통해서 정의되어야 합니다.\n",
        "\n",
        "함수형 모델과 하위 클래스를 통해 정의된 모델의 주요 다른점은 [이곳](https://medium.com/tensorflow/what-are-symbolic-and-imperative-apis-in-tensorflow-2-0-dfccecb01021)에 설명되어 있습니다.\n",
        "\n",
        "[이곳](https://www.tensorflow.org/alpha/guide/keras/functional)을 방문해서, 함수형 API에 대해 좀 더 배워볼 수 있습니다.\n",
        "\n",
        "연구의 작업 흐름에서, 객체지향 모델과 함수형 모델을 섞어쓰는 자신을 종종 발견하게 될지도 모릅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p0KngmPTScu",
        "colab_type": "text"
      },
      "source": [
        "단일 입력과 출력을 가지는 Layer을 이용해서, 여러 층으로 구성된 모델에 대하여 `Sequential` 클래스를 사용할 수도 있습니다. 이 클래스는 Layer의 목록을 `Model`로 변환해 줍니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNhTY6frTaP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "\n",
        "model = Sequential([Linear(32), Dropout(0.5), Linear(10)])\n",
        "\n",
        "y = model(tf.ones((2, 16)))\n",
        "assert y.shape == (2, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cydf3i_FFXlh",
        "colab_type": "text"
      },
      "source": [
        "## Loss 클래스\n",
        "\n",
        "Keras는 넓은 범위의 미리 정의된 손실함수에 대한 Loss 클래스를 제공합니다. 이는 `BinaryCrossentropy`, `CategoricalCrossentropy`, `KLDivergence`등과 같은 것이 포함되며 다음과 같이 작동합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "019Nm1eWFaUO",
        "colab_type": "code",
        "outputId": "2224754c-20c7-480b-aa24-f87c82495558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bce = tf.keras.losses.BinaryCrossentropy()\n",
        "y_true = [0., 0., 1., 1.]  # 목표 (레이블)\n",
        "y_pred = [1., 1., 1., 0.]  # 예측 결과\n",
        "loss = bce(y_true, y_pred)\n",
        "print('손실:', loss.numpy())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "손실: 11.522857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smbxFMGXY83U",
        "colab_type": "text"
      },
      "source": [
        "Loss 클래스는 상태를 가지지 않습니다. 즉, `__call__`의 출력은 입력에 대한 함수일 뿐입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNLZsnswFbE_",
        "colab_type": "text"
      },
      "source": [
        "## Metric 클래스\n",
        "\n",
        "또한, Keras는 넓은 범위의 미리 정의된 평가지표 함수에 대한 Metric 클래스를 제공합니다. 이는 `BinaryAccuracy`, `AUC`, `FalsePositives`등과 같은것을 포함합니다.\n",
        "\n",
        "Loss와는 다르게, Metric은 상태를 가집니다. `update_state` 메소드를 사용해서 상태를 갱신하고, `result`를 사용해서 스칼라형태의 결과값을 요청할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dUZkMWATKMC",
        "colab_type": "code",
        "outputId": "cce25335-1b91-4800-bd52-396a0e6b5ba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "m = tf.keras.metrics.AUC()\n",
        "m.update_state([0, 1, 1, 1], [0, 1, 0, 0])\n",
        "print('중간 결과: ', m.result().numpy())\n",
        "\n",
        "m.update_state([1, 1, 1, 1], [0, 1, 1, 0])\n",
        "print('최종 결과: ', m.result().numpy())"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "중간 결과:  0.6666667\n",
            "최종 결과:  0.71428573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doUSrciie2Px",
        "colab_type": "text"
      },
      "source": [
        "내부 상태는 `metric.reset_states`에 의해 초기화될 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwx7DjFBZ-C-",
        "colab_type": "text"
      },
      "source": [
        "`Metric` 클래스의 하위 클래스를 만들어서, 여러분만의 평가지표 함수를 손쉽게 만들수도 있습니다:\n",
        "\n",
        "- `__init__`내의 상태 변수를 생성합니다\n",
        "- `update_state`내에서 인자로써 주어진 `y_true`와 `y_pred`를 이용해서 변수를 갱신합니다\n",
        "- `result`내에서 평가지표의 결과를 반환합니다\n",
        "- `reset_states`내에서 상태를 초기화 합니다\n",
        "\n",
        "다음은 이 방법을 보여주기 위한 목적으로, `BinaryTruePositive` 평가지표에 대한 구현하고 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVByLrJyaBx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BinaryTruePositives(tf.keras.metrics.Metric):\n",
        "\n",
        "  def __init__(self, name='binary_true_positives', **kwargs):\n",
        "    super(BinaryTruePositives, self).__init__(name=name, **kwargs)\n",
        "    self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    y_true = tf.cast(y_true, tf.bool)\n",
        "    y_pred = tf.cast(y_pred, tf.bool)\n",
        "\n",
        "    values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n",
        "    values = tf.cast(values, self.dtype)\n",
        "    if sample_weight is not None:\n",
        "      sample_weight = tf.cast(sample_weight, self.dtype)\n",
        "      sample_weight = tf.broadcast_weights(sample_weight, values)\n",
        "      values = tf.multiply(values, sample_weight)\n",
        "    self.true_positives.assign_add(tf.reduce_sum(values))\n",
        "\n",
        "  def result(self):\n",
        "    return self.true_positives\n",
        "\n",
        "  def reset_states(self):\n",
        "    self.true_positive.assign(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0PdvHdAdQl0",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer 클래스 & 빠른 end-to-end 학습 반복문\n",
        "\n",
        "앞서 보여진 선형회귀 예제에서 작성한, 경사하강시 변수값을 직접 갱신하는 방법은 일반적으로 하지 않아도 됩니다. 보통은 `SGD`, `RMSprop`, 또는 `Adam`등과 같이 Keras에서 미리 제공되는 Optimizer 중 하나를 사용하면 됩니다.\n",
        "\n",
        "아래는 MNIST 데이터에 대해서, Loss, Metric 클래스와 Optimizer가 모두 함께 사용되는 예를 보여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jNl1ykEdkj8",
        "colab_type": "code",
        "outputId": "03d350db-d230-4cda-cb93-e29584a68d20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# 데이터셋를 준비합니다\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train[:].reshape(60000, 784).astype('float32') / 255\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "# 간단한 분류를 위한 모델의 인스턴스를 만듭니다\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(10)\n",
        "])\n",
        "\n",
        "# 정수형 레이블을 인자로 받아들이는, 로지스틱 Loss의 인스턴스를 만듭니다\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# 정확도에 대한 Metric의 인스턴스를 만듭니다\n",
        "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# Optimizer의 인스턴스를 만듭니다\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# 데이터셋의 데이터 배치를 순회합니다\n",
        "for step, (x, y) in enumerate(dataset):\n",
        "  \n",
        "  # GradientTape 열어줍니다\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    # 순방향 전파(forward)를 수행합니다\n",
        "    logits = model(x)\n",
        "\n",
        "    # 현재 배치에 대한 손실값을 측정합니다\n",
        "    loss_value = loss(y, logits)\n",
        "     \n",
        "  # 손실에 대한 가중치의 경사도를 계산합니다\n",
        "  gradients = tape.gradient(loss_value, model.trainable_weights)\n",
        "  \n",
        "  # 모델의 가중치를 갱신합니다\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "  # 현재까지 수행된 전체에 대한 모델의 정확도를 갱신합니다\n",
        "  accuracy.update_state(y, logits)\n",
        "  \n",
        "  # 로그를 출력합니다\n",
        "  if step % 100 == 0:\n",
        "    print('단계(Step):', step)\n",
        "    print('마지막 단계(Step)의 손실:', float(loss_value))\n",
        "    print('지금까지 수행된 전체에 대한 정확도:', float(accuracy.result()))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "단계(Step): 0\n",
            "마지막 단계(Step)의 손실: 2.3885810375213623\n",
            "지금까지 수행된 전체에 대한 정확도: 0.09375\n",
            "단계(Step): 100\n",
            "마지막 단계(Step)의 손실: 0.4133984446525574\n",
            "지금까지 수행된 전체에 대한 정확도: 0.8394182920455933\n",
            "단계(Step): 200\n",
            "마지막 단계(Step)의 손실: 0.30982598662376404\n",
            "지금까지 수행된 전체에 대한 정확도: 0.876166045665741\n",
            "단계(Step): 300\n",
            "마지막 단계(Step)의 손실: 0.11299564689397812\n",
            "지금까지 수행된 전체에 대한 정확도: 0.8959198594093323\n",
            "단계(Step): 400\n",
            "마지막 단계(Step)의 손실: 0.1841564029455185\n",
            "지금까지 수행된 전체에 대한 정확도: 0.9083930850028992\n",
            "단계(Step): 500\n",
            "마지막 단계(Step)의 손실: 0.08552507311105728\n",
            "지금까지 수행된 전체에 대한 정확도: 0.9160117506980896\n",
            "단계(Step): 600\n",
            "마지막 단계(Step)의 손실: 0.06116322800517082\n",
            "지금까지 수행된 전체에 대한 정확도: 0.9223169684410095\n",
            "단계(Step): 700\n",
            "마지막 단계(Step)의 손실: 0.11729268729686737\n",
            "지금까지 수행된 전체에 대한 정확도: 0.9269570112228394\n",
            "단계(Step): 800\n",
            "마지막 단계(Step)의 손실: 0.10659649968147278\n",
            "지금까지 수행된 전체에 대한 정확도: 0.9301459193229675\n",
            "단계(Step): 900\n",
            "마지막 단계(Step)의 손실: 0.028563685715198517\n",
            "지금까지 수행된 전체에 대한 정확도: 0.9340836405754089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIJYBrXoekXD",
        "colab_type": "text"
      },
      "source": [
        "`SparseCategoricalAccuracy` Metric 인스턴스를 재사용해서 테스트 반복문을 구현할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl6FKvqbeqX9",
        "colab_type": "code",
        "outputId": "f02f8dd6-3f1e-4d3d-a70a-b0befe329f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "x_test = x_test[:].reshape(10000, 784).astype('float32') / 255\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = test_dataset.batch(128)\n",
        "\n",
        "accuracy.reset_states()  # 이 코드는 Metric의 내부 상태를 초기화 합니다\n",
        "\n",
        "for step, (x, y) in enumerate(test_dataset):\n",
        "  logits = model(x)\n",
        "  accuracy.update_state(y, logits)\n",
        "\n",
        "print('최종 테스트 정확도:', float(accuracy.result()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최종 테스트 정확도: 0.9557999968528748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEP7jzC8YVWy",
        "colab_type": "text"
      },
      "source": [
        "## `add_loss` 메소드\n",
        "\n",
        "때로는 순방향 전파(forward) 수행 중 손실값을 계산해 보고 싶을 수 있습니다 (특히, 정규화(regularization) 손실에 대해서). Keras는 어느시점에서든지 손실값을 계산할 수 있게 해 주고, `add_loss` 메소드를 통해 이 손실값을 재귀적으로 계속 추적할 수 있게 해 줍니다.\n",
        "\n",
        "다음은 입력에 대한 L2 노름에 기반한 희소 정규화(regularization) 손실을 추가하는 Layer의 예를 보여줍니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbBVP--jYgHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ActivityRegularization(Layer):\n",
        "  \"\"\"활성 희소 정규화 손실(activity sparsity regularization loss)을 생성하는 Layer 입니다\"\"\"\n",
        "  \n",
        "  def __init__(self, rate=1e-2):\n",
        "    super(ActivityRegularization, self).__init__()\n",
        "    self.rate = rate\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    # 입력값에 기반하는\n",
        "    # `add_loss`를 사용해서 정규화 손실을 생성합니다\n",
        "    self.add_loss(self.rate * tf.reduce_sum(tf.square(inputs)))\n",
        "    return inputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4qoQk7abK5v",
        "colab_type": "text"
      },
      "source": [
        "`add_loss`를 이용해서 추가된 손실값은 `Layer` 또는 `Model`의 리스트형 속성인 `.losses`를 통해서 접근이 가능합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlJc_4pbbQ2N",
        "colab_type": "code",
        "outputId": "a9501d61-49c2-4069-f0ac-43951c3b6fe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "class SparseMLP(Layer):\n",
        "  \"\"\"희소 정규화 손실을 가지는 선형 계층을 쌓아올린 Layer 입니다\"\"\"\n",
        "\n",
        "  def __init__(self, output_dim):\n",
        "      super(SparseMLP, self).__init__()\n",
        "      self.dense_1 = layers.Dense(32, activation=tf.nn.relu)\n",
        "      self.regularization = ActivityRegularization(1e-2)\n",
        "      self.dense_2 = layers.Dense(output_dim)\n",
        "\n",
        "  def call(self, inputs):\n",
        "      x = self.dense_1(inputs)\n",
        "      x = self.regularization(x)\n",
        "      return self.dense_2(x)\n",
        "    \n",
        "\n",
        "mlp = SparseMLP(1)\n",
        "y = mlp(tf.ones((10, 10)))\n",
        "\n",
        "print(mlp.losses)  # float32 자료형의 단일 스칼라값을 가지는 리스트 입니다"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tf.Tensor: id=186023, shape=(), dtype=float32, numpy=0.3541786>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkI3GA2TbWvY",
        "colab_type": "text"
      },
      "source": [
        "이 손실값들은 순방향 전파(forward)의 시작점에 있는 최상위 Layer로부터 초기화되며 축적되지 않습니다. 따라서 `layer.losses`는 항상 마지막 순방향 전파동안 생성된 손실값만을 가지게 됩니다. 학습 반복문을 작성할 때, 일반적으로 경사도 계산 이전에 이 손실값들에 대한 합산을 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m0xNYGEbZe2",
        "colab_type": "code",
        "outputId": "9a1c60f7-8f79-4d27-8cb2-1a592736917f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# *마지막* 순방향 전파에 해당하는 손실값들 입니다\n",
        "mlp = SparseMLP(1)\n",
        "mlp(tf.ones((10, 10)))\n",
        "assert len(mlp.losses) == 1\n",
        "mlp(tf.ones((10, 10)))\n",
        "assert len(mlp.losses) == 1  # 축적되지 않습니다\n",
        "\n",
        "# 이 손실값들을 학습 반복문에서 사용하는법을 보여줍니다\n",
        "\n",
        "# 데이터셋을 준비합니다\n",
        "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train.reshape(60000, 784).astype('float32') / 255, y_train))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "# 새로운 MLP를 만듭니다\n",
        "mlp = SparseMLP(10)\n",
        "\n",
        "# Loss와 Optimizer를 만듭니다\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "\n",
        "for step, (x, y) in enumerate(dataset):\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    # 순방향 전파를 수행합니다\n",
        "    logits = mlp(x)\n",
        "\n",
        "    # 현재 배치에 대한 외부의 손실값을 계산합니다\n",
        "    loss = loss_fn(y, logits)\n",
        "    \n",
        "    # 순방향 전파시 생성된 손실값을 더해줍니다 \n",
        "    loss += sum(mlp.losses)\n",
        "     \n",
        "    # 해당 손실에 대한 가중치의 경사도를 계산합니다\n",
        "    gradients = tape.gradient(loss, mlp.trainable_weights)\n",
        "  \n",
        "  # 모델의 가중치를 갱신합니다\n",
        "  optimizer.apply_gradients(zip(gradients, mlp.trainable_weights))\n",
        "  \n",
        "  # 로그를 출력합니다\n",
        "  if step % 100 == 0:\n",
        "    print(step, float(loss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 3.8689327239990234\n",
            "100 2.310004234313965\n",
            "200 2.2619950771331787\n",
            "300 2.1776585578918457\n",
            "400 2.0352156162261963\n",
            "500 1.9956769943237305\n",
            "600 2.027062177658081\n",
            "700 1.9948246479034424\n",
            "800 2.0250766277313232\n",
            "900 1.7551041841506958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zecO65f2Ph7O",
        "colab_type": "text"
      },
      "source": [
        "## 자세한 end-to-end 예제: Variational AutoEncoder (VAE)\n",
        "\n",
        "기초적인 내용의 공부를 잠시 미뤄두고, 약간 더 어려운 예제를 살펴보고 싶다면, [여기에 소개된 VAE](https://www.tensorflow.org/guide/keras/custom_layers_and_models#putting_it_all_together_an_end-to-end_example)에 대한 구현의 예제를 확인해 보시기 바랍니다. 이는 여러분이 지금까지 배워왔던 모든것의 내용을 담고 있습니다:\n",
        "\n",
        "- `Layer`의 하위 클래스를 만드는것\n",
        "- 재귀적으로 Layer를 구성하는것\n",
        "- Loss 및 Metric 클래스에 대한것\n",
        "- `add_loss`\n",
        "- `GradientTape`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V0yRrfYFuVT",
        "colab_type": "text"
      },
      "source": [
        "## 미리 정의된 학습 반복문을 사용하는것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNwAjgEXPpnP",
        "colab_type": "text"
      },
      "source": [
        "간단한 케이스에 대해서 조차 여러분이 스스로 저수준의 학습 반복문을 매번 작성해야 한다면, 이는 어리석은 일일지도 모릅니다. Keras는 미리 정의된 학습 반복문을 `Model` 클래스에서 제공합니다. 사용하고자 한다면, `Model`의 하위 클래스를 만들거나 `Functional(함수형)` 또는 `Sequential(순차형)` 모델을 생성하면 됩니다.\n",
        "\n",
        "이를 보여주기 위해서, 앞서 만들어둔 MNIST의 예를 재사용 해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omdNf2x4jovv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터셋을 준비합니다\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(64)\n",
        "\n",
        "# 간단한 분류모델의 인스턴스를 만듭니다\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(10)\n",
        "])\n",
        "\n",
        "# 정수형 레이블을 인자로 받아들이는, 로지스틱 Loss의 인스턴스를 만듭니다\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# 정확도에 대한 Metric의 인스턴스를 만듭니다\n",
        "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# Optimizer의 인스턴스를 만듭니다\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYU5PkaLiriO",
        "colab_type": "text"
      },
      "source": [
        "가장 첫 번째로, `compile` 메소드를 호출하여 Optimizer, Loss, 모니터링하기 위한 Metric을 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo6GhvzjJjdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98zDjMPej06U",
        "colab_type": "text"
      },
      "source": [
        "그리고 나선 `fit` 메소드를 호출하고, 이 때 데이터를 전달해 줍니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OdztL4nj4ed",
        "colab_type": "code",
        "outputId": "6fc4eb46-6dd9-475c-ef60-343f1e6c5937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "model.fit(dataset, epochs=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.2215 - sparse_categorical_accuracy: 0.9346\n",
            "Epoch 2/3\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0863 - sparse_categorical_accuracy: 0.9730\n",
            "Epoch 3/3\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0542 - sparse_categorical_accuracy: 0.9830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0e203d7e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZc2ss8qln1p",
        "colab_type": "text"
      },
      "source": [
        "이게 끝입니다! 이제는 테스트를 해 봅시다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0-XQbxOlqB3",
        "colab_type": "code",
        "outputId": "c0ec4ea4-74bc-454c-ad2f-a0fc1f3394c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "x_test = x_test[:].reshape(10000, 784).astype('float32') / 255\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = test_dataset.batch(128)\n",
        "\n",
        "loss, acc = model.evaluate(test_dataset)\n",
        "print('손실:', loss, '정확도:', acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 0s 4ms/step - loss: 0.0951 - sparse_categorical_accuracy: 0.9720\n",
            "손실: 0.09513797635828511 정확도: 0.972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkmbEn55nV7y",
        "colab_type": "text"
      },
      "source": [
        "`fit`이 수행되는 동안 검증용 데이터셋에 대한 Loss와 Metric을 모니터링 하는것 또한 가능합니다.\n",
        "\n",
        "또한, Numpy형의 배열에 대해서도 직접적으로 `fit`을 호출할 수 있습니다. 따라서 데이터셋에 대한 변환이 필요 없습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q8UuNivngVe",
        "colab_type": "code",
        "outputId": "83f2ff29-cd0d-4218-e4d2-30351b792c9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "\n",
        "num_val_samples = 10000\n",
        "x_val = x_train[-num_val_samples:]\n",
        "y_val = y_train[-num_val_samples:]\n",
        "x_train = x_train[:-num_val_samples]\n",
        "y_train = y_train[:-num_val_samples]\n",
        "\n",
        "# 간단한 분류모델의 인스턴스를 만듭니다\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(10)\n",
        "])\n",
        "\n",
        "# 정수형 레이블을 인자로 받아들이는, 로지스틱 Loss의 인스턴스를 만듭니다\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# 정확도에 대한 Metric의 인스턴스를 만듭니다\n",
        "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# Optimizer의 인스턴스를 만듭니다\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=[accuracy])\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          epochs=3,\n",
        "          batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "50000/50000 [==============================] - 5s 102us/sample - loss: 0.2427 - sparse_categorical_accuracy: 0.9282 - val_loss: 0.1173 - val_sparse_categorical_accuracy: 0.9649\n",
            "Epoch 2/3\n",
            "50000/50000 [==============================] - 5s 92us/sample - loss: 0.0931 - sparse_categorical_accuracy: 0.9717 - val_loss: 0.1063 - val_sparse_categorical_accuracy: 0.9682\n",
            "Epoch 3/3\n",
            "50000/50000 [==============================] - 5s 92us/sample - loss: 0.0604 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.0820 - val_sparse_categorical_accuracy: 0.9767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0ddc191208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88ExjKfCo7aP",
        "colab_type": "text"
      },
      "source": [
        "## Callbacks\n",
        "\n",
        "`fit`이 가지는 간단하지만 훌륭한 기능 중 하나로, [callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/)을 사용해서 학습과 평가 도중 일어나는 일에 대한 사용자 정의화가 가능합니다.\n",
        "\n",
        "Callback은 객체의 한 종류로, 학습 중간 중간에 호출(예를들어, 매 배치마다 또는 매 epoch마다) 되며 어떤 작업을 수행합니다.\n",
        "\n",
        "미리 정의된 여러가지 Callback이 존재합니다. `ModelCheckpoint`는 학습도중 매 epoch마다 모델을 저장하고, `EarlyStopping`은 검증용 평가지표(metrics)가 향상되지 않을 때 학습을 중단시킵니다.\n",
        "\n",
        "물론, 손쉽게 [여러분만의 callback을 작성할 수도 있습니다](https://www.tensorflow.org/guide/keras/custom_callback).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAylVdYJqcZ3",
        "colab_type": "code",
        "outputId": "e33395c0-832c-4f39-9d05-c3c74f8f3dad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# 간단한 분류모델의 인스턴스를 만듭니다\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(256, activation=tf.nn.relu),\n",
        "  layers.Dense(10)\n",
        "])\n",
        "\n",
        "# 정수형 레이블을 인자로 받아들이는, 로지스틱 Loss의 인스턴스를 만듭니다\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# 정확도에 대한 Metric의 인스턴스를 만듭니다\n",
        "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# Optimizer의 인스턴스를 만듭니다\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=[accuracy])\n",
        "\n",
        "# 몇가지 Callback의 인스턴스를 만듭니다\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(),\n",
        "             tf.keras.callbacks.ModelCheckpoint(filepath='my_model.keras',\n",
        "                                                save_best_only=True)]\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          epochs=30,\n",
        "          batch_size=64,\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 5s 100us/sample - loss: 0.2408 - sparse_categorical_accuracy: 0.9294 - val_loss: 0.1155 - val_sparse_categorical_accuracy: 0.9666\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 5s 91us/sample - loss: 0.0928 - sparse_categorical_accuracy: 0.9710 - val_loss: 0.1049 - val_sparse_categorical_accuracy: 0.9682\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 5s 90us/sample - loss: 0.0614 - sparse_categorical_accuracy: 0.9807 - val_loss: 0.0958 - val_sparse_categorical_accuracy: 0.9725\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 4s 89us/sample - loss: 0.0450 - sparse_categorical_accuracy: 0.9857 - val_loss: 0.0838 - val_sparse_categorical_accuracy: 0.9753\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 5s 92us/sample - loss: 0.0364 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.0946 - val_sparse_categorical_accuracy: 0.9734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0ddbcaccf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxINLLGitX_n",
        "colab_type": "text"
      },
      "source": [
        "# 작별 인사\n",
        "\n",
        "저는 이 가이드가 여러분에게 TensorFlow2.0과 Keras로 무엇을 할 수 있는지 알려주는 좋은 오버뷰가 되길 희망합니다!\n",
        "\n",
        "TensorFlow와 Keras는 단일 작업 흐름만을 대변하는게 아니라는 것을 기억하세요. 사용성과 유연성이라는 트레이드오프를 가지는 여러 범위의 작업흐름을 지원합니다. 예를 들어서, `fit` 메소드를 사용하는것이 사용자정의 학습 반복문을 작성하는것보다 훨씬 쉽지만, `fit`은 연구에서 필요한 미세한 조절이 가능한 수준까지를 제공하진 못합니다.\n",
        "\n",
        "따라서, 여러분의 일에 맞는 알맞은 툴을 사용하세요!\n",
        "\n",
        "Keras의 중심이 되는 원칙은 \"복잡도의 점진적인 공개\" 입니다. 매우 쉽게 시작할 수 있고, 점점 더 많은 부분을 밑바닥에서 부터 구현해야 하는 작업흐름에 대해서 점진적으로 좀 더 깊이 들여다보고, 그렇게함으로써 완전한 제어를 할 수 있게 됩니다.\n",
        "\n",
        "\n",
        "이 사실은 모델의 정의와 모델의 학습 모두에 적용되는 것입니다.\n",
        "\n",
        "![모델의 정의: 작업 흐름의 범위](https://drive.google.com/uc?export=view&id=1bTHrw-OXaKqnJI-DVGG04suWHVOl8UVj)\n",
        "\n",
        "![모델의 학습: 작업 흐름의 범위](https://drive.google.com/uc?export=view&id=1a6oMJ9IKyMg19JX7NkihyOfzdiJo5Mpq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfO_uy61upRm",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## 이 다음으로 보면 좋을만한 것들\n",
        "\n",
        "이 가이드 다음으로, 여러분이 관심을 가질만한 주제가 더 있습니다:\n",
        "\n",
        "- [저장과 직렬화](https://www.tensorflow.org/guide/keras/save_and_serialize)\n",
        "- [다중 GPUs에서의 분산 학습](https://www.tensorflow.org/guide/distributed_training)\n",
        "- [임베디드 시스템이나 안드로이드 개발에 활용하기 위해 모델을 TFLite로 내보내기](https://www.tensorflow.org/lite/convert/python_api#converting_a_keras_model_)\n",
        "- [브라우져에서의 개발에 활용하기 위해 모델을 TensorFlow.js로 내보내기](https://www.tensorflow.org/js/tutorials/conversion/import_keras)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FelcNL4gO4mP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}